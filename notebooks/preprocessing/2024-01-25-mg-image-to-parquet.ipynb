{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image to Parquet\n",
    "\n",
    "Convert images to binary and save them into a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/26 14:37:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f2440220dc0>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config(\"spark.hadoop.fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "    .master(\"local[*]\").appName(\"Images2Parquet\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Base directory using pathlib\n",
    "curr_dir = Path(os.getcwd())\n",
    "base_dir = curr_dir.parents[1]\n",
    "data_dir = base_dir / \"data\" / \"SnakeCLEF2023-small_size\" / \"2023\"\n",
    "num_folders = 20\n",
    "\n",
    "# Ensure base directory exists\n",
    "if not data_dir.is_dir():\n",
    "    raise FileNotFoundError(f\"Data directory {data_dir} does not exist.\")\n",
    "\n",
    "# Getting subfolders\n",
    "subfolders = sorted([f.name for f in data_dir.iterdir() if f.is_dir()])[:num_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema for the DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, BinaryType, StringType\n",
    "schema = StructType([\n",
    "    StructField(\"path\", StringType(), True),\n",
    "    StructField(\"image_binary_data\", BinaryType(), True)\n",
    "])\n",
    "\n",
    "# Function to convert image to binary\n",
    "def image_to_binary(image_path):\n",
    "    with open(image_path, 'rb') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SnakeCLEF2023-small_size/2023/Acanthophis_antarcticus/250558438.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Acanthophis_antarcticus/250558444.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Acanthophis_laevis/250489238.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Acanthophis_praelongus/252303073.jpg\n",
      "SnakeCLEF2023-small_size/2023/Acanthophis_rugosus/250956644.jpg\n",
      "SnakeCLEF2023-small_size/2023/Acrochordus_granulatus/254291444.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Acrochordus_granulatus/253984428.jpg\n",
      "SnakeCLEF2023-small_size/2023/Acrochordus_granulatus/253984330.jpg\n",
      "SnakeCLEF2023-small_size/2023/Acrochordus_granulatus/253984113.jpg\n",
      "SnakeCLEF2023-small_size/2023/Afrotyphlops_mucruso/252625785.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Afrotyphlops_mucruso/252624489.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Afrotyphlops_mucruso/252625813.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Afrotyphlops_mucruso/252625754.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Afrotyphlops_schlegelii/250454737.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Afrotyphlops_schlegelii/250454780.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Afrotyphlops_schlegelii/250454819.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Agkistrodon_russeolus/252723504.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Agkistrodon_russeolus/254328301.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Agkistrodon_russeolus/254328285.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_farnsworthi/251341911.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_fasciolata/250695079.jpg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_fasciolata/250694950.jpg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_fasciolata/250695081.jpg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_fasciolata/250695080.jpg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_fusca/253378981.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_fusca/253378970.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_malabarica/253890852.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_malabarica/253975627.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_malabarica/253975642.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_nasuta/253734742.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_nasuta/252656375.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_nasuta/254406165.jpg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_oxyrhynca/252601270.jpg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_oxyrhynca/252601305.jpg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_oxyrhynca/254430964.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250933661.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/251113447.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805123.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805112.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805130.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805142.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805079.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805021.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805042.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805060.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805027.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805038.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805083.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250933648.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805104.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805071.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805067.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805088.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805098.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250933640.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805032.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805052.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805116.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/250805138.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Ahaetulla_prasina/252657757.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Aipysurus_duboisii/252493681.jpg\n",
      "SnakeCLEF2023-small_size/2023/Aipysurus_duboisii/251243310.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Aipysurus_duboisii/251243295.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Aipysurus_duboisii/251085028.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Aipysurus_laevis/251406420.jpg\n",
      "SnakeCLEF2023-small_size/2023/Aipysurus_laevis/251406390.jpg\n",
      "SnakeCLEF2023-small_size/2023/Amblyodipsas_polylepis/253488680.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Amphiesma_monticola/252504093.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Amphiesma_stolatum/254199387.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Amphiesma_stolatum/254199394.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Amphiesma_stolatum/251806189.jpeg\n",
      "SnakeCLEF2023-small_size/2023/Amphiesma_stolatum/251676108.jpeg\n"
     ]
    }
   ],
   "source": [
    "# Create an empty RDD\n",
    "image_rdd = spark.sparkContext.emptyRDD()\n",
    "\n",
    "# Loop through subfolders and process images\n",
    "for folder in subfolders:\n",
    "    folder_path = data_dir / folder\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = folder_path / img_name\n",
    "        relative_path = img_path.relative_to(base_dir)  # Get relative path\n",
    "        relative_path = str(relative_path).split(\"data/\")[-1]\n",
    "        print(relative_path)\n",
    "        binary_data = image_to_binary(str(img_path))\n",
    "        image_rdd = image_rdd.union(spark.sparkContext.parallelize([(relative_path, binary_data)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                path|   image_binary_data|\n",
      "+--------------------+--------------------+\n",
      "|SnakeCLEF2023-sma...|[FF D8 FF E0 00 1...|\n",
      "|SnakeCLEF2023-sma...|[FF D8 FF E0 00 1...|\n",
      "|SnakeCLEF2023-sma...|[FF D8 FF E0 00 1...|\n",
      "|SnakeCLEF2023-sma...|[FF D8 FF E0 00 1...|\n",
      "|SnakeCLEF2023-sma...|[FF D8 FF E0 00 1...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:======================================================>(285 + 3) / 288]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in image_df: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Convert RDD to DataFrame\n",
    "image_df = spark.createDataFrame(image_rdd, schema)\n",
    "\n",
    "# Show the first few rows of image_df\n",
    "image_df.show(n=5)\n",
    "\n",
    "# Count the number of rows in image_df\n",
    "row_count = image_df.count()\n",
    "print(f\"Number of rows in image_df: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory for parquet_files folder\n",
    "data_dir = Path(os.getcwd()).parents[1] / \"data\"\n",
    "\n",
    "# Create \"parquet_files\" directory if it doesn't exist\n",
    "parquet_dir = data_dir / \"parquet_files\"\n",
    "os.makedirs(parquet_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the Parquet file\n",
    "parquet_file_path = parquet_dir / \"images_data.parquet\"\n",
    "\n",
    "# Save the DataFrame as a Parquet file\n",
    "image_df.write.mode(\"overwrite\").parquet(str(parquet_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_of_parquet(dir_path):\n",
    "    total_size = 0\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            total_size += os.path.getsize(os.path.join(root, file))\n",
    "    return total_size\n",
    "\n",
    "# Get the size of the Parquet file (directory)\n",
    "parquet_size = get_size_of_parquet(parquet_file_path)\n",
    "print(f\"Size of Parquet file: {parquet_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GCS path\n",
    "gcs_path = \"gs://dsgt-clef-snakeclef-2024/data/parquet_files/image_data\"\n",
    "\n",
    "# Write the DataFrame to GCS\n",
    "image_df.write.mode(\"overwrite\").parquet(gcs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
