{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create parquet files in GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/07 14:20:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/02/07 14:20:17 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "24/02/07 14:20:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://snakeclef-dev.us-central1-a.c.dsgt-clef-2024.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6efddcd150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snakeclef.utils import get_spark\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "spark = get_spark()\n",
    "display(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dsgt-clef-snakeclef-2024/data/parquet_files/\n",
      "\n",
      "gs://dsgt-clef-snakeclef-2024/data/parquet_files/:\n",
      "gs://dsgt-clef-snakeclef-2024/data/parquet_files/\n",
      "gs://dsgt-clef-snakeclef-2024/data/parquet_files/SnakeCLEF2023-train-small_size/\n",
      "gs://dsgt-clef-snakeclef-2024/data/parquet_files/acm_image_data_test_repartition/\n"
     ]
    }
   ],
   "source": [
    "# Get list of stored filed in cloud bucket\n",
    "! gcloud storage ls gs://dsgt-clef-snakeclef-2024/data/parquet_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current directory\n",
    "curr_dir = Path(os.getcwd())\n",
    "\n",
    "# Change to the project directory to run the scripts\n",
    "os.chdir(curr_dir.parents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def process_dataset(dataset_name, meta_dataset_name, delete_dataset: bool = True):\n",
    "    # Define the base directory\n",
    "    base_dir = \"/mnt/data\"\n",
    "\n",
    "    # Define the path for the script and Python script\n",
    "    script_path = \"./scripts/download_extract_dataset.sh\"\n",
    "    python_script_path = \"./snakeclef/images_to_parquet.py\"\n",
    "\n",
    "    # Define the GCS paths\n",
    "    gcs_path = f\"gs://dsgt-clef-snakeclef-2024/raw/{dataset_name}.tar.gz\"\n",
    "    output_path = f\"gs://dsgt-clef-snakeclef-2024/data/parquet_files/{dataset_name}\"\n",
    "\n",
    "    # Adjust the dataset_name for the --dataset-name parameter\n",
    "    adjusted_dataset_name = (\n",
    "        dataset_name.replace(\"train-\", \"\")\n",
    "        .replace(\"val-\", \"\")\n",
    "        .replace(\"pubtest\", \"pubtest\")\n",
    "    )\n",
    "\n",
    "    # Download and extract the dataset\n",
    "    os.system(f\"{script_path} {gcs_path} {base_dir}\")\n",
    "\n",
    "    # Create parquet file\n",
    "    os.system(\n",
    "        f\"python {python_script_path} --output-path {output_path} --dataset-name {adjusted_dataset_name} --meta-dataset-name {meta_dataset_name}\"\n",
    "    )\n",
    "\n",
    "    if delete_dataset:\n",
    "        # Delete dataset locally before loading the next one\n",
    "        local_data_path = f\"./data/{adjusted_dataset_name}\"\n",
    "        local_tar_path = f\"./data/{dataset_name}.tar.gz\"\n",
    "        os.system(f\"rm -rf {local_data_path}\")\n",
    "        os.system(f\"rm -f {local_tar_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train small size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset names\n",
    "data_name = \"SnakeCLEF2023-train-small_size\"\n",
    "meta_name = \"SnakeCLEF2023-TrainMetadata-iNat\"\n",
    "\n",
    "# Process the data\n",
    "process_dataset(dataset_name=data_name, meta_dataset_name=meta_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train medium size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset URL: gs://dsgt-clef-snakeclef-2024/raw/SnakeCLEF2023-train-medium_size.tar.gz\n",
      "Downloading dataset to: /mnt/data\n",
      "Permissions set for /mnt/data.\n",
      "Downloading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mount: /mnt/data: /dev/nvme0n1 already mounted on /mnt/data.\n",
      "Copying gs://dsgt-clef-snakeclef-2024/raw/SnakeCLEF2023-train-medium_size.tar.gz to file:///mnt/data/SnakeCLEF2023-train-medium_size.tar.gz\n",
      "  \n",
      ".........................................................................................................................................................................................................................\n",
      "\n",
      "Average throughput: 410.1MiB/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset...\n",
      "Dataset extracted to /mnt/data.\n",
      "Final contents of /mnt/data:\n",
      "SnakeCLEF2023-medium_size\n",
      "SnakeCLEF2023-train-medium_size.tar.gz\n",
      "lost+found\n",
      "tmp\n",
      "Disk usage and free space:\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "/dev/root        49G   43G  6.1G  88% /\n",
      "tmpfs           7.4G     0  7.4G   0% /dev/shm\n",
      "tmpfs           3.0G  1.1M  3.0G   1% /run\n",
      "tmpfs           5.0M     0  5.0M   0% /run/lock\n",
      "/dev/sda15      105M  6.1M   99M   6% /boot/efi\n",
      "/dev/nvme0n1    369G   35G  315G  11% /mnt/data\n",
      "tmpfs           1.5G  8.0K  1.5G   1% /run/user/1005\n",
      "Script completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/07 14:24:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/02/07 14:24:15 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "24/02/07 14:24:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/02/07 14:24:16 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/02/07 14:24:32 WARN SharedInMemoryCache: Evicting cached table partition metadata from memory due to size constraints (spark.sql.hive.filesourcePartitionFileCacheSize = 262144000 bytes). This may impact query planning performance.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define dataset names\n",
    "data_name = \"SnakeCLEF2023-train-medium_size\"\n",
    "meta_name = \"SnakeCLEF2023-TrainMetadata-iNat\"\n",
    "\n",
    "# Process the data\n",
    "process_dataset(dataset_name=data_name, meta_dataset_name=meta_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verifying the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----+--------------------+-------------+--------------------+--------------+-------+----+--------+------+\n",
      "|          image_path|                path|         folder_name|year|       binomial_name|    file_name|                data|observation_id|endemic|code|class_id|subset|\n",
      "+--------------------+--------------------+--------------------+----+--------------------+-------------+--------------------+--------------+-------+----+--------+------+\n",
      "|1993/Phrynonax_po...|/SnakeCLEF2023-sm...|SnakeCLEF2023-sma...|1993| Phrynonax_polylepis|102870166.jpg|[FF D8 FF E0 00 1...|      64030606|  false|  EC|    1287| train|\n",
      "|1995/Acrantophis_...|/SnakeCLEF2023-sm...|SnakeCLEF2023-sma...|1995|Acrantophis_dumerili| 99694826.jpg|[FF D8 FF E0 00 1...|      62240606|   true|  MG|      11| train|\n",
      "|1996/Ficimia_stre...|/SnakeCLEF2023-sm...|SnakeCLEF2023-sma...|1996|   Ficimia_streckeri| 29265846.jpg|[FF D8 FF E0 00 1...|       2442697|  false|  US|     703| train|\n",
      "+--------------------+--------------------+--------------------+----+--------------------+-------------+--------------------+--------------+-------+----+--------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    BinaryType,\n",
    "    IntegerType,\n",
    "    BooleanType,\n",
    ")\n",
    "\n",
    "# Define the schema based on the provided structure\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"image_path\", StringType(), True),\n",
    "        StructField(\"path\", StringType(), True),\n",
    "        StructField(\"folder_name\", StringType(), False),\n",
    "        StructField(\"year\", StringType(), True),\n",
    "        StructField(\"binomial_name\", StringType(), True),\n",
    "        StructField(\"file_name\", StringType(), True),\n",
    "        StructField(\"data\", BinaryType(), True),\n",
    "        StructField(\"observation_id\", IntegerType(), True),\n",
    "        StructField(\"endemic\", BooleanType(), True),\n",
    "        StructField(\"code\", StringType(), True),\n",
    "        StructField(\"class_id\", IntegerType(), True),\n",
    "        StructField(\"subset\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the GCS path to the Parquet file\n",
    "small_gcs_path = (\n",
    "    \"gs://dsgt-clef-snakeclef-2024/data/parquet_files/SnakeCLEF2023-train-small_size\"\n",
    ")\n",
    "medium_gcs_path = (\n",
    "    \"gs://dsgt-clef-snakeclef-2024/data/parquet_files/SnakeCLEF2023-train-medium_size\"\n",
    ")\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "sml_df = spark.read.schema(schema).parquet(small_gcs_path)\n",
    "med_df = spark.read.schema(schema).parquet(medium_gcs_path)\n",
    "\n",
    "# Show the data (for example, first few rows)\n",
    "sml_df.show(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows in small not in medium\n",
    "diff_sml_med = sml_df.exceptAll(med_df)\n",
    "\n",
    "# Rows in medium not in small\n",
    "diff_med_sml = med_df.exceptAll(sml_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_med_sml.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_sml_med.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+----------------------------------------------------------------+------------------------+----+--------------------+-------------+----------------------------------------------------------------------------------------------------+--------------+-------+----+--------+------+\n",
      "|                            image_path|                                                            path|             folder_name|year|       binomial_name|    file_name|                                                                                                data|observation_id|endemic|code|class_id|subset|\n",
      "+--------------------------------------+----------------------------------------------------------------+------------------------+----+--------------------+-------------+----------------------------------------------------------------------------------------------------+--------------+-------+----+--------+------+\n",
      "|1993/Phrynonax_polylepis/102870166.jpg|/SnakeCLEF2023-small_size/1993/Phrynonax_polylepis/102870166.jpg|SnakeCLEF2023-small_size|1993| Phrynonax_polylepis|102870166.jpg|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 01 00 01 00 00 FF DB 00 43 00 0A 07 07 08 07 06 0A ...|      64030606|  false|  EC|    1287| train|\n",
      "|1995/Acrantophis_dumerili/99694826.jpg|/SnakeCLEF2023-small_size/1995/Acrantophis_dumerili/99694826.jpg|SnakeCLEF2023-small_size|1995|Acrantophis_dumerili| 99694826.jpg|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 01 00 01 00 00 FF E2 02 40 49 43 43 5F 50 52 4F 46 ...|      62240606|   true|  MG|      11| train|\n",
      "|   1996/Ficimia_streckeri/29265846.jpg|   /SnakeCLEF2023-small_size/1996/Ficimia_streckeri/29265846.jpg|SnakeCLEF2023-small_size|1996|   Ficimia_streckeri| 29265846.jpg|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 01 00 01 00 00 FF E2 0C 58 49 43 43 5F 50 52 4F 46 ...|       2442697|  false|  US|     703| train|\n",
      "+--------------------------------------+----------------------------------------------------------------+------------------------+----+--------------------+-------------+----------------------------------------------------------------------------------------------------+--------------+-------+----+--------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-----------------------------------------------------------------+-------------------------+----+---------------------+------------+----------------------------------------------------------------------------------------------------+--------------+-------+-------+--------+------+\n",
      "|                            image_path|                                                             path|              folder_name|year|        binomial_name|   file_name|                                                                                                data|observation_id|endemic|   code|class_id|subset|\n",
      "+--------------------------------------+-----------------------------------------------------------------+-------------------------+----+---------------------+------------+----------------------------------------------------------------------------------------------------+--------------+-------+-------+--------+------+\n",
      "|1991/Elaphe_quatuorlineata/3000817.jpg|/SnakeCLEF2023-medium_size/1991/Elaphe_quatuorlineata/3000817.jpg|SnakeCLEF2023-medium_size|1991|Elaphe_quatuorlineata| 3000817.jpg|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 01 01 2C 01 2C 00 00 FF DB 00 43 00 01 01 01 01 01 01 01 ...|       2670525|  false|     HR|     619| train|\n",
      "|1998/Lampropeltis_alterna/81017330.jpg|/SnakeCLEF2023-medium_size/1998/Lampropeltis_alterna/81017330.jpg|SnakeCLEF2023-medium_size|1998| Lampropeltis_alterna|81017330.jpg|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 01 00 01 00 00 FF DB 00 43 00 05 03 04 04 04 03 05 ...|      51008724|  false|unknown|     860| train|\n",
      "| 1999/Bothrops_bilineatus/86795779.jpg| /SnakeCLEF2023-medium_size/1999/Bothrops_bilineatus/86795779.jpg|SnakeCLEF2023-medium_size|1999|  Bothrops_bilineatus|86795779.jpg|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 01 00 01 00 00 FF DB 00 43 00 1B 12 14 17 14 11 1B ...|      54545055|  false|     GF|     225| train|\n",
      "+--------------------------------------+-----------------------------------------------------------------+-------------------------+----+---------------------+------------+----------------------------------------------------------------------------------------------------+--------------+-------+-------+--------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sml_df.show(n=3, truncate=100)\n",
    "med_df.show(n=3, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+---------------------------------------------------------------------+-------------------------+----+------------------------+-------------+----------------------------------------------------------------------------------------------------+--------------+-------+----+--------+------+\n",
      "|                                image_path|                                                                 path|              folder_name|year|           binomial_name|    file_name|                                                                                                data|observation_id|endemic|code|class_id|subset|\n",
      "+------------------------------------------+---------------------------------------------------------------------+-------------------------+----+------------------------+-------------+----------------------------------------------------------------------------------------------------+--------------+-------+----+--------+------+\n",
      "|2019/Hypsiglena_ochrorhynchus/68486239.jpg|/SnakeCLEF2023-medium_size/2019/Hypsiglena_ochrorhynchus/68486239.jpg|SnakeCLEF2023-medium_size|2019|Hypsiglena_ochrorhynchus| 68486239.jpg|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 01 00 01 00 00 FF DB 00 43 00 03 02 02 02 02 02 03 ...|      43142963|   true|  US|     834| train|\n",
      "|  2020/Hierophis_viridiflavus/95020192.jpg|  /SnakeCLEF2023-medium_size/2020/Hierophis_viridiflavus/95020192.jpg|SnakeCLEF2023-medium_size|2020|  Hierophis_viridiflavus| 95020192.jpg|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 01 00 01 00 00 FF E2 0C 58 49 43 43 5F 50 52 4F 46 ...|      59455956|  false|  HR|     799| train|\n",
      "|         2023/Bothrops_atrox/252406801.jpg|         /SnakeCLEF2023-medium_size/2023/Bothrops_atrox/252406801.jpg|SnakeCLEF2023-medium_size|2023|          Bothrops_atrox|252406801.jpg|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 01 00 01 00 00 FF DB 00 43 00 03 02 02 03 02 02 03 ...|     146644293|  false|  VE|     224| train|\n",
      "|  2020/Dolichophis_jugularis/116532834.jpg|  /SnakeCLEF2023-medium_size/2020/Dolichophis_jugularis/116532834.jpg|SnakeCLEF2023-medium_size|2020|   Dolichophis_jugularis|116532834.jpg|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 01 00 01 00 00 FF E2 02 34 49 43 43 5F 50 52 4F 46 ...|      71563925|  false|  CY|     564| train|\n",
      "|         2022/Naja_sumatrana/217276261.jpg|         /SnakeCLEF2023-medium_size/2022/Naja_sumatrana/217276261.jpg|SnakeCLEF2023-medium_size|2022|          Naja_sumatrana|217276261.jpg|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 01 00 01 00 00 FF DB 00 43 00 02 01 01 01 01 01 02 ...|     127941056|  false|  MY|    1129| train|\n",
      "+------------------------------------------+---------------------------------------------------------------------+-------------------------+----+------------------------+-------------+----------------------------------------------------------------------------------------------------+--------------+-------+----+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform an anti-join to find rows in med_df that do not exist in sml_df based on image_path\n",
    "differences = med_df.join(sml_df, \"image_path\", \"left_anti\")\n",
    "\n",
    "# Show the results\n",
    "differences.show(n=5, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differences.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 80:======================================>                  (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----------+----+-------------+---------+----+--------------+-------+----+--------+------+\n",
      "|image_path|path|folder_name|year|binomial_name|file_name|data|observation_id|endemic|code|class_id|subset|\n",
      "+----------+----+-----------+----+-------------+---------+----+--------------+-------+----+--------+------+\n",
      "+----------+----+-----------+----+-------------+---------+----+--------------+-------+----+--------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "sml_df.where(col(\"image_path\") == \"2019/Hypsiglena_ochrorhynchus/68486239.jpg\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
