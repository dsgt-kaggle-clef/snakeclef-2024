{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/08 17:27:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/08 17:27:22 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "24/05/08 17:27:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://snakeclef-dev.us-central1-a.c.dsgt-clef-2024.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>plantclef</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x76165694c370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snakeclef.utils import get_spark\n",
    "from pyspark.sql import functions as F\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spark = get_spark()\n",
    "display(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path and dataset names\n",
    "gcs_path = \"gs://dsgt-clef-snakeclef-2024/data\"\n",
    "dct_emb_path = \"process/training_v1/dino_dct/data\"\n",
    "train_path = \"parquet_files/SnakeCLEF2023-train-small_size\"\n",
    "\n",
    "# Define the GCS path to the embedding files\n",
    "dct_gcs_path = f\"{gcs_path}/{dct_emb_path}\"\n",
    "train_gcs_path = f\"{gcs_path}/{train_path}\"\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "dct_df = spark.read.parquet(dct_gcs_path)\n",
    "train_df = spark.read.parquet(train_gcs_path)\n",
    "\n",
    "# Show the data\n",
    "dct_df.show(n=5, truncate=50)\n",
    "train_df.show(n=5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation\n",
    "grouped_df = (\n",
    "    dct_df.groupBy(\"observation_id\")\n",
    "    .agg(F.count(\"observation_id\").alias(\"n\"))\n",
    "    .orderBy(F.col(\"n\").desc())\n",
    ")\n",
    "\n",
    "# Action\n",
    "grouped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param\n",
    "num_top_species = 5\n",
    "\n",
    "# Get top species DF\n",
    "top_species = [\n",
    "    int(row[\"species_id\"]) for row in grouped_df.limit(num_top_species).collect()\n",
    "]\n",
    "print(f\"Top {num_top_species} species ids: {top_species}\")\n",
    "\n",
    "subset_df = dct_df.filter(F.col(\"species_id\").isin(top_species)).select(\n",
    "    [\"image_name\", \"species_id\", \"dct_embedding\"]\n",
    ")\n",
    "\n",
    "subset_df = subset_df.join(train_df, \"image_name\", \"inner\").select(\n",
    "    [subset_df.species_id, train_df.species, subset_df.dct_embedding]\n",
    ")\n",
    "\n",
    "subset_df.show(20)\n",
    "print(subset_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert to Pandas DF\n",
    "pandas_df = subset_df.select([\"dct_embedding\", \"species\"]).toPandas()\n",
    "\n",
    "# Extract features and labels\n",
    "emb_df = np.stack(pandas_df[\"dct_embedding\"].values)\n",
    "scaled_emb = StandardScaler().fit_transform(emb_df)\n",
    "labels = pandas_df[\"species\"].tolist()\n",
    "\n",
    "# UMAP reduction\n",
    "reducer = umap.UMAP(n_neighbors=15, n_components=2, metric=\"euclidean\", random_state=42)\n",
    "embedding = reducer.fit_transform(scaled_emb)  # NumPy array with shape (n_samples, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster(pandas_df, embeddings, algorithm_name):\n",
    "    # Plot the data\n",
    "    fig, ax = plt.subplots(figsize=(6.4, 4.8), dpi=200)\n",
    "    fig.suptitle(\n",
    "        f\"{algorithm_name} projection of top 5 plant species\",\n",
    "        fontsize=14,\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "\n",
    "    # Create a scatter plot, color-coded by new species_idx\n",
    "    colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\"]\n",
    "    top_species_idx = pandas_df[\"species\"].value_counts().nlargest(5).index\n",
    "    species_to_color = {species: colors[i] for i, species in enumerate(top_species_idx)}\n",
    "\n",
    "    # Map species IDs to colors for plotting\n",
    "    color_list = pandas_df[\"species\"].map(species_to_color).tolist()\n",
    "\n",
    "    for species, color in species_to_color.items():\n",
    "        # Select embeddings for the current species\n",
    "        idx = pandas_df[\"species\"] == species\n",
    "        ax.scatter(\n",
    "            embeddings[idx, 0],\n",
    "            embeddings[idx, 1],\n",
    "            c=color,\n",
    "            # cmap=\"tab10\",\n",
    "            label=species,\n",
    "            s=5,\n",
    "            alpha=0.7,\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "    ax.grid(color=\"blue\", linestyle=\"--\", linewidth=1, alpha=0.2)\n",
    "    ax.legend(loc=\"best\", title=\"Species Name\", fontsize=\"small\")\n",
    "    for spine in [\"top\", \"right\", \"bottom\", \"left\"]:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(pandas_df, embedding, algorithm_name=\"UMAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pacmap\n",
    "\n",
    "# PaCMAP\n",
    "pacmap_embedding = pacmap.PaCMAP(\n",
    "    n_components=2, n_neighbors=15, MN_ratio=0.5, FP_ratio=2.0\n",
    ")\n",
    "\n",
    "# fit the data\n",
    "pacmap_transformed = pacmap_embedding.fit_transform(scaled_emb, init=\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(pandas_df, pacmap_transformed, algorithm_name=\"PaCMAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
